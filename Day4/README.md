
This repository contains my completed regression tasks, covering simple linear regression, multiple regression, polynomial regression, outlier impact, and regularization techniques** using **Python (sklearn, Matplotlib, Seaborn, NumPy, Pandas).  

Task 1: Basic Linear Regression 
- Used a dataset with one predictor and one outcome variable.  
- Cleaned and split data into training and testing sets.  
- Trained a linear regression model using `sklearn`.  
- Made predictions and evaluated using R-squared.  

Output: A simple model with predictions and R-squared score.  


Task 2: Data Visualization for Regression  
- Loaded dataset and plotted scatter plot of data points.  
- Fitted a regression line to visualize relationships.  
- Used Matplotlib/Seaborn for visualization with proper labels and title.  

Output: A regression plot showing data points and best-fit line.  


Task 3: Multiple Linear Regression  
- Selected a dataset with multiple independent variables.  
- Preprocessed the dataset (handling missing values, encoding categorical data).  
- Fitted a multiple linear regression model.  
- Made predictions and evaluated performance.  

Output: Predictions based on multiple features with performance metrics.  


Task 4: Model Assessment  
- Used R-squared and RMSE to evaluate model accuracy.  
- Interpreted how well the model fits the data.  

Output: Performance metrics explaining model accuracy and error.  

Task 5: Feature Impact Analysis  
- Analyzed the importance of each feature in the regression model.  
- Used model coefficients and feature importance techniques.  
- Reported on which features contributed most to predictions.  

Output: Insights into the most predictive features.  


Task 6: Polynomial Regression  
- Used a dataset with non-linear relationships.  
- Transformed predictor variable(s) into polynomial features.  
- Trained and compared polynomial vs. linear regression.  
- Visualized both models for comparison.  

Output: Graph comparing polynomial and linear regression fits.  


Task 7: Outlier Impact 
- Identified outliers in the dataset using statistical methods.  
- Trained regression models with and without outliers.  
- Compared model performance differences.  

Output: Analysis showing how outliers affect regression accuracy.  


Task 8: Regularization Implementation  
- Implemented Lasso and Ridge regression to prevent overfitting.  
- Compared results with standard linear regression.  
- Analyzed how regularization reduces model complexity.  

Output: A regularized model with reduced overfitting.  

